{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üó∫Ô∏è GeoPandas (gpd)"
      ],
      "metadata": {
        "id": "q7hJEYWvG0_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GeoPandas is a powerful extension of the Pandas library that makes it easy to work with geographic data in Python. While Pandas handles tabular data (like CSV files) with rows and columns, GeoPandas adds a special `geometry` column that stores spatial features such as points (e.g., cities), lines (e.g., roads), and polygons (e.g., country or neighborhood boundaries). This allows you to analyze and visualize real-world locations directly within your \"GeoDataFrame\". GeoPandas makes complex spatial operations‚Äîlike filtering data within a region, joining attributes to shapes, or mapping patterns across space‚Äîintuitive and accessible using familiar Pandas-like commands.\n",
        "\n",
        "However, because GeoPandas is not part of the default Python or Colab installation, we have to install it each time we start a new Google Colab session."
      ],
      "metadata": {
        "id": "SkfqKyK7dc1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing GeoPandas\n",
        "!pip install geopandas"
      ],
      "metadata": {
        "id": "tYXXWDbUG-fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries Important for Making Maps\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "rwlpwEK9g37k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GeoDataFrames‚Äîspatially-aware versions of pandas DataFrames‚Äîcan be loaded from a variety of sources. The most common include:\n",
        "\n",
        "1.   built-in or external Python packages like `geodatasets`, which provide easy access to curated shapefiles;\n",
        "2.    direct links to online shapefiles or zipped shapefile URLs, such as those hosted by Natural Earth or the U.S. Census Bureau; and\n",
        "3. locally downloaded ZIP files that you extract and load using GeoPandas. Many reliable sources of geographic data include [Natural Earth](https://www.naturalearthdata.com/), [U.S. Census TIGER/Line](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html), and [GADM](https://gadm.org/).\n",
        "\n",
        "\n",
        "Choosing the right approach depends on your data source, internet access, and the level of control you need over your file handling. To learn how to load these GeoDataFrames (and some of the pros and cons of each technique), we'll start with [Natural Earth](https://www.naturalearthdata.com/):"
      ],
      "metadata": {
        "id": "70Lp831ZSkED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading GeoDataFrames (naturalearthdata.com)"
      ],
      "metadata": {
        "id": "nXjFVdy8emBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The website [naturalearthdata.com](https://www.naturalearthdata.com/downloads/) is a public domain geospatial data repository that provides free, high-quality geographic datasets for global-scale mapping and analysis. Maintained by a coalition of cartographers and the North American Cartographic Information Society (NACIS), it offers a wide range of vector and raster datasets, including:\n",
        "\n",
        "* Administrative Boundaries (countries, states/provinces)\n",
        "* Physical Features (rivers, coastlines, land, oceans)\n",
        "* Cultural Features (urban areas, populated places, roads)\n",
        "\n",
        "Datasets are available at [three scales](https://www.naturalearthdata.com/downloads/) ‚Äî 1:10m, 1:50m, and 1:110m ‚Äî to support a variety of use cases from high-resolution local maps to simple world overviews. Specifically, [naturalearthdata.com](https://www.naturalearthdata.com/downloads/) has spatial information down to the state/province boundaries for all countries, as well as cities, infrastructure (i.e., roads, railways, airports, shipping ports), urban areas, and timezones."
      ],
      "metadata": {
        "id": "H1_fzpk-Af87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natural Earth Data: From a Python Package**\n",
        "\n",
        "This method involves accessing pre-packaged geographic datasets through Python libraries like `geodatasets`, which are often designed to work seamlessly with GeoPandas. These datasets are curated, well-formatted, and ready to use without requiring manual downloading or file handling. This is an excellent option for beginners or for quickly prototyping with reliable base maps such as countries, continents, or U.S. states.\n",
        "\n",
        "‚úÖ Pros:\n",
        "* Fast and easy to load‚Äîno need to find or manage files manually\n",
        "* Datasets are clean, standardized, and often come with documentation\n",
        "* Good for education, demos, or global/regional mapping\n",
        "\n",
        "‚ùå Cons:\n",
        "* Limited selection‚Äîoften only includes basic political boundaries at coarse resolution\n",
        "* Not always up-to-date or customizable\n",
        "* May not include local-level or specialized data (e.g., counties, neighborhoods, parcels)\n",
        "\n",
        "Use this method when you want a quick, built-in solution or when teaching or exploring geographic concepts without dealing with external files."
      ],
      "metadata": {
        "id": "AowNUrXIl889"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the easiest way to get started with geographic data. Packages like `geodatasets` provide clean, ready-to-use datasets directly inside Python‚Äîno downloading, unzipping, or uploading required. All you need to do is install `!pip install geodatasets`, and then `from geodatasets import get_path`. This will allow you call many different GeoDataFrames from the package `geodatasets`, including `\"naturalearth.land\"`, which is an outline of the world's landmasses."
      ],
      "metadata": {
        "id": "Sq64cmIX1DxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages (if not already installed)\n",
        "!pip install geodatasets"
      ],
      "metadata": {
        "id": "xYIBLFBF5McH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import geopandas as gpd\n",
        "from geodatasets import get_path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load built-in country-level map from geodatasets\n",
        "path = get_path(\"naturalearth.land\")\n",
        "gdf_world = gpd.read_file(path)"
      ],
      "metadata": {
        "id": "gWFoymMoxkRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If your curious about the other GeoDataFrames stored in `geodatasets`, you can list them by running `print(list(geodatasets.data.flatten().keys()))`."
      ],
      "metadata": {
        "id": "8sQZrqMR3NHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geodatasets\n",
        "\n",
        "# View all dataset keys\n",
        "print(list(geodatasets.data.flatten().keys()))"
      ],
      "metadata": {
        "id": "INCkPeZG3f_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The primary downside of using packages is that you are limited by the data that has been built into the package. The package `geodatasets` in particular doesn't contain higher resolution or state/province level data that can be found on [naturalearthdata.com](https://www.naturalearthdata.com/downloads/)."
      ],
      "metadata": {
        "id": "huRzsXUH4Xv1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a GeoDataFrame, there is a `geometry` column stores spatial objects‚Äîsuch as shapes that define the location, boundaries, or paths of geographic features. These objects are essential for mapping and performing spatial operations. The most common geometry types include:\n",
        "* `POINT`: A single coordinate (e.g., a city location).\n",
        "* `MULTIPOINT`: A collection of individual points.\n",
        "* `LINESTRING`: A sequence of connected points forming a line (e.g., a road or river).\n",
        "* `MULTILINESTRING`: Multiple lines grouped together.\n",
        "* `POLYGON`: A closed area defined by a boundary (e.g., a state or lake).\n",
        "* `MULTIPOLYGON`: Multiple polygons combined (e.g., an archipelago or country with many islands).\n",
        "\n",
        "These geometries allow GeoPandas to represent, analyze, and visualize spatial relationships in data. You can view this GeoDataFrame by running the name of the GeoDataFrame (oftentimes labeled as `gdf`) in your code cell:"
      ],
      "metadata": {
        "id": "wv4LaqHUu_3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_world"
      ],
      "metadata": {
        "id": "iqbZSf7rqRx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natural Earth Data: From a URL**\n",
        "\n",
        "This method involves directly loading geographic data from a URL, such as a zipped shapefile hosted online (e.g., from [Natural Earth](https://www.naturalearthdata.com/), [U.S. Census TIGER/Line](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html), or [GADM](https://gadm.org/)). With this approach, you can programmatically download and extract datasets using tools like `requests`, `curl`, and `zipfile`, and then load them into a `GeoDataFrame` using GeoPandas. This is especially useful for reproducible workflows, remote access, or using authoritative, high-resolution data.\n",
        "\n",
        "‚úÖ Pros:\n",
        "* Access the most recent and detailed datasets directly from authoritative sources\n",
        "* Reproducible‚Äîeverything from download to plot can be scripted\n",
        "* No need to manually upload or manage files in the workspace\n",
        "\n",
        "‚ùå Cons:\n",
        "* Requires a reliable internet connection and understanding of URL structure\n",
        "* May involve extra steps (e.g., unzipping, handling encoding issues)\n",
        "* Some sources use links that change or expire, or may block access without headers\n",
        "\n",
        "Use this method when you need up-to-date or official spatial data and want to automate the download and loading process in your notebook."
      ],
      "metadata": {
        "id": "LbAXMzYUzML7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have identified the map you want to create (e.g., \"Admin 0 - Countries\" in [1:110m Cultural Vectors](https://www.naturalearthdata.com/downloads/110m-cultural-vectors/)), right click on the link to `Download countries` and select `Copy link address`. However, before we can use this link, we have to modify the url so that it is a direct file link by replacing `https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/` with `https://naciscdn.org/naturalearth/`:\n",
        "\n",
        "* Original: `https://www.naturalearthdata.com/http//www.naturalearthdata.com/download/110m/cultural/ne_110m_admin_0_countries.zip`\n",
        "* Modified: `https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip`\n",
        "\n",
        "Once we have the correct link, we can use `gpd.read_file()` to read our url and plot our map:"
      ],
      "metadata": {
        "id": "MUG7R0D0GQ9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Global countries from Natural Earth (110m scale)\n",
        "url = \"https://naciscdn.org/naturalearth/110m/cultural/ne_110m_admin_0_countries.zip\"\n",
        "gdf_countries = gpd.read_file(url)"
      ],
      "metadata": {
        "id": "TQVELv5B-Z0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_countries"
      ],
      "metadata": {
        "id": "L6CXBPiP_7zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Natural Earth Data: From a .zip File**\n",
        "\n",
        "This method involves manually downloading a shapefile (usually in ZIP format) from a source like Natural Earth, U.S. Census TIGER/Line, or GADM, then uploading it into your environment (e.g., the `/content/` folder in Google Colab), extracting the files, and loading the `.shp` file using GeoPandas. It gives you full control over the data and is especially helpful when working offline or with datasets that require manual inspection.\n",
        "\n",
        "‚úÖ Pros:\n",
        "* Full control over dataset selection, resolution, and metadata\n",
        "* Works offline once files are downloaded\n",
        "* Ideal for custom, local, or specialized datasets not available through packages or URLs\n",
        "\n",
        "‚ùå Cons:\n",
        "* Manual steps‚Äîrequires downloading, unzipping, and uploading files\n",
        "* File management can be tedious in environments like Google Colab\n",
        "* Requires careful attention to maintaining all necessary shapefile components (e.g., `.shp`, `.shx`, `.dbf`)\n",
        "\n",
        "Use this method when working with local files, teaching from a pre-curated dataset, or using high-resolution or region-specific shapefiles that aren't easily accessible online."
      ],
      "metadata": {
        "id": "vIpqFO7y0Vk9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, this is the most robust way to load a GeoDataFrame (if you have access to save a local copy of a .zip file). Let's work with a different map (e.g., \"Admin 1 - States, Provinces\" in [1:10m Cultural Vectors](https://www.naturalearthdata.com/downloads/10m-cultural-vectors/)). This time, you can regular click on the link to `Download countries`. After the download has completed, upload this .zip file to the `/contents/` folder in your Google Colab. With this .zip file uploaded, all you need to do is modify the `zip_path` in the code below to create your state/province level map."
      ],
      "metadata": {
        "id": "gtLBdAz3GWhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Path to uploaded ZIP file\n",
        "zip_path = \"/content/ne_10m_admin_1_states_provinces.zip\"\n",
        "extract_path = \"/content/natural_earth_extract\"\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Find the .shp file (assumes there's only one)\n",
        "for file in os.listdir(extract_path):\n",
        "    if file.endswith(\".shp\"):\n",
        "        shp_path = os.path.join(extract_path, file)\n",
        "\n",
        "# Load with GeoPandas\n",
        "gdf_states = gpd.read_file(shp_path)"
      ],
      "metadata": {
        "id": "gl_QC5Yu-ghX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_states"
      ],
      "metadata": {
        "id": "K_79A1VGAZe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging GeoDataFrames and DataFrames"
      ],
      "metadata": {
        "id": "2srCJWV8em1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading GeoDataFrames (census.gov)"
      ],
      "metadata": {
        "id": "bjYXu3OV3ZIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The U.S. Census TIGER/Line Shapefiles are a comprehensive public resource maintained by the U.S. Census Bureau that provides detailed spatial data for mapping geographic and administrative features across the United States. These datasets are specifically designed for demographic analysis, policy research, and GIS applications, and include:\n",
        "\n",
        "* Administrative Boundaries (states, counties, congressional districts, census tracts, ZIP code tabulation areas)\n",
        "* Transportation Networks (roads, railroads, pipelines)\n",
        "* Hydrography (rivers, lakes, coastal features)\n",
        "* Landmarks and Legal Areas (schools, parks, military installations, tribal lands)\n",
        "\n",
        "Available in multiple spatial resolutions‚Äîsuch as 500k (generalized), 5m, and 20m‚Äîthese shapefiles offer varying levels of detail suitable for national, state, or local analysis. TIGER/Line files are regularly updated and are accessible via direct download or integrated into tools like ArcGIS and Python's geopandas. The data provides full coverage of U.S. territories and is widely used for election mapping, redistricting, urban planning, and socio-demographic studies."
      ],
      "metadata": {
        "id": "bBR03uURSVye"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**US Census: Download .zip File from URL**\n",
        "\n",
        "To access geographic boundary data from the U.S. Census Bureau, you can download shapefiles from their [TIGER/Line database](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html), which provides detailed spatial data like counties, states, and census tracts. The provided code downloads a ZIP file containing county-level boundaries at 1:5 million resolution, extracts it, and prepares it for mapping in Python. Here's what each part does:\n",
        "\n",
        "* `url`: Direct link to the ZIP file from the Census TIGER/Line repository.\n",
        "\n",
        "* `curl`: Command-line tool used to download the file to your local `/content/` folder in Google Colab (useful when `requests.get()` fails due to SSL issues).\n",
        "\n",
        "* `zipfile.ZipFile`: Unzips the contents so you can load them with `geopandas.read_file()`.\n",
        "\n",
        "Once extracted, the shapefile consists of multiple files with the same base name (e.g., `cb_2021_us_county_5m.*`)‚Äîthese collectively define the geospatial dataset."
      ],
      "metadata": {
        "id": "QSVev4aLTR2e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How to Read the File Name**:\n",
        "\n",
        "Take cb_2021_us_county_5m.shp as an example:\n",
        "* `cb`: Cartographic Boundary (as opposed to raw TIGER data)\n",
        "* `2021`: Year of the dataset\n",
        "* `us`: Country or region code (United States)\n",
        "* `county`: Geographic level (others might be state, tract, etc.)\n",
        "* `5m`: Resolution (1:5 million scale). There is also `20m` (low resolution) and `5k` (high resolution).\n",
        "\n",
        "These files are always accompanied by `.shp`, `.shx`, `.dbf`, and sometimes `.prj`, which together form the complete shapefile used by GIS tools like GeoPandas."
      ],
      "metadata": {
        "id": "B6-p9mvWDPni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code downloads and extracts U.S. county boundary shapefiles from the U.S. Census Bureau's TIGER/Line database. It uses the `curl` command to fetch the `.zip` file containing 5m resolution county boundaries and saves it locally in a Colab directory. The `zipfile` module then unpacks the contents so they can be loaded into a GeoDataFrame for mapping or spatial analysis."
      ],
      "metadata": {
        "id": "AIpVQIgCDmGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define paths for 5m resolution counties\n",
        "url = \"https://www2.census.gov/geo/tiger/GENZ2021/shp/cb_2021_us_county_5m.zip\"\n",
        "zip_path = \"/content/us_counties_5m.zip\"\n",
        "extract_path = \"/content/us_counties_5m\"\n",
        "\n",
        "# Use curl to download the ZIP file\n",
        "!curl -o {zip_path} \"{url}\"\n",
        "\n",
        "# Extract ZIP contents\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "L0lwZKP5LyjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code loads and visualizes New Jersey's county boundaries using shapefile data previously extracted from the U.S. Census TIGER/Line dataset. It reads the shapefile into a GeoDataFrame, filters the data by the `STATEFP` column (New Jersey's FIPS code is `\"34\"`), and then uses Matplotlib to plot the map. The result is a clean, annotated visualization of New Jersey's counties at 1:5 million scale resolution."
      ],
      "metadata": {
        "id": "42o07rrpD1jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import geopandas as gpd\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load Shapefile\n",
        "shp_path = os.path.join(extract_path, \"cb_2021_us_county_5m.shp\")\n",
        "gdf_counties = gpd.read_file(shp_path)"
      ],
      "metadata": {
        "id": "jJVDDjV6A7QA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading DataFrames (\"census\" Package)"
      ],
      "metadata": {
        "id": "vTs3Kc4mEBTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A powerful way to access official U.S. demographic and socioeconomic data is directly from your Python environment. Packages like `census`, `us`, and `censusdata` let you connect to the U.S. Census Bureau's APIs and download tabular datasets‚Äîsuch as population, education, income, housing, and more‚Äîwithout manually visiting the Census website. These tools are especially useful for retrieving data from the Decennial Census and the American Community Survey (ACS).\n",
        "\n",
        "To get started, first install the necessary packages:"
      ],
      "metadata": {
        "id": "O3gTNunw2-Jp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Census Packages\n",
        "!pip install censusdata\n",
        "!pip install census\n",
        "!pip install us"
      ],
      "metadata": {
        "id": "kNiHGCsM_Xi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing these packages gives you access to demographic, social, and economic data from the U.S. Census Bureau‚Äîparticularly from datasets like:\n",
        "* ACS (American Community Survey): yearly updates on income, education, housing, age, and more.\n",
        "* Decennial Census: population counts every 10 years.\n",
        "* Population Estimates Program: yearly population totals.\n",
        "* Other topical surveys (e.g., commuting, health insurance, veteran status).\n",
        "\n",
        "Specifically, these packages give you access to:\n",
        "* `censusdata`:\tDownload and explore ACS/Census data directly into Pandas, with built-in metadata tools.\n",
        "* `census`:\tQuery the Census API directly using an API key (needed for some datasets).\n",
        "* `us`:\tEasily access FIPS codes and metadata for U.S. states and territories (states.NJ.fips)."
      ],
      "metadata": {
        "id": "MAWRrpBYlfEO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import censusdata\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "# Load the county-level shapefile\n",
        "gdf_counties = gpd.read_file(\"/content/us_counties_5m/\")\n",
        "\n",
        "# Download ACS 5-year estimate data for total population in 2021\n",
        "# Variable B01003_001E = Total population\n",
        "df_census = censusdata.download(\n",
        "    src=\"acs5\",\n",
        "    year=2021,\n",
        "    geo=censusdata.censusgeo([(\"state\", \"*\"), (\"county\", \"*\")]),\n",
        "    var=[\"B01003_001E\"]\n",
        ")d\n",
        "\n",
        "# Reset index and rename columns\n",
        "df_census.reset_index(inplace=True)\n",
        "df_census[\"STATEFP\"] = df_census[\"index\"].apply(lambda x: x.params()[0][1])\n",
        "df_census[\"COUNTYFP\"] = df_census[\"index\"].apply(lambda x: x.params()[1][1])\n",
        "df_census = df_census.rename(columns={\"B01003_001E\": \"Total_Pop\"})"
      ],
      "metadata": {
        "id": "jEU1zzABnlQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What columns do `gdf_counties` and `df_census` have in common?\n"
      ],
      "metadata": {
        "id": "p7rShs1h2nH-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the columns\n",
        "print(\"gdf_counties:\", gdf_counties.columns)\n",
        "print(\"\\n\")\n",
        "print(\"df_census:\", df_census.columns)"
      ],
      "metadata": {
        "id": "Dtp4TTkTAeaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use these overlapping columns (`\"STATEFP\"` and `\"COUNTYFP\"`) to merge the two GeoDataFrame (`gdf_counties`) and DataFrame (`df_census`):"
      ],
      "metadata": {
        "id": "Gyk1HlZ3EVgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge with geodataframe (on FIPS codes)\n",
        "gdf_merged = gdf_counties.merge(df_census, on=[\"STATEFP\", \"COUNTYFP\"])\n",
        "\n",
        "gdf_merged"
      ],
      "metadata": {
        "id": "BNjQOFjCAEX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Filtering GeoDataSets"
      ],
      "metadata": {
        "id": "OL59C9JeG7yx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our merged GeoDataFrame, we may want to filter for a specific state (`\"STATEFP\"`). In order to do this, need to know how to interpret the \"State Federal Processing Code\" or `STATEFP` (see table below).\n",
        "\n",
        "| State            | STATEFP | State                    | STATEFP |\n",
        "|------------------|---------|--------------------------|---------|\n",
        "| Alabama          | 01      | Nebraska                 | 31      |\n",
        "| Alaska           | 02      | Nevada                   | 32      |\n",
        "| Arizona          | 04      | New Hampshire            | 33      |\n",
        "| Arkansas         | 05      | New Jersey               | 34      |\n",
        "| California       | 06      | New Mexico               | 35      |\n",
        "| Colorado         | 08      | New York                 | 36      |\n",
        "| Connecticut      | 09      | North Carolina           | 37      |\n",
        "| Delaware         | 10      | North Dakota            | 38      |\n",
        "| Florida          | 12      | Ohio                     | 39      |\n",
        "| Georgia          | 13      | Oklahoma                 | 40      |\n",
        "| Hawaii           | 15      | Oregon                   | 41      |\n",
        "| Idaho            | 16      | Pennsylvania             | 42      |\n",
        "| Illinois         | 17      | Rhode Island             | 44      |\n",
        "| Indiana          | 18      | South Carolina           | 45      |\n",
        "| Iowa             | 19      | South Dakota            | 46      |\n",
        "| Kansas           | 20      | Tennessee                | 47      |\n",
        "| Kentucky         | 21      | Texas                    | 48      |\n",
        "| Louisiana        | 22      | Utah                     | 49      |\n",
        "| Maine            | 23      | Vermont                  | 50      |\n",
        "| Maryland         | 24      | Virginia                 | 51      |\n",
        "| Massachusetts    | 25      | Washington               | 53      |\n",
        "| Michigan         | 26      | West Virginia           | 54      |\n",
        "| Minnesota        | 27      | Wisconsin                | 55      |\n",
        "| Mississippi      | 28      | Wyoming                  | 56      |\n",
        "| Missouri         | 29      |                          |         |\n",
        "| Montana          | 30      |                          |         |\n",
        "\n",
        "| Territory                | STATEFP |\n",
        "|--------------------------|---------|\n",
        "| American Samoa           | 60      |\n",
        "| Guam                     | 66      |\n",
        "| Northern Mariana Islands | 69      |\n",
        "| Puerto Rico              | 72      |\n",
        "| U.S. Virgin Islands      | 78      |\n",
        "\n",
        "Similar to DataFrames, you can filter GeoDataFrames the same way. For example, if we want to filter for a specific state, we can do the following:"
      ],
      "metadata": {
        "id": "Hm7fvl_RHy3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for New Jersey using STATEFP (FIPS code for NJ is '34')\n",
        "gdf_nj = gdf_merged[gdf_merged[\"STATEFP\"] == \"34\"]"
      ],
      "metadata": {
        "id": "Ra0q5spOmTC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gdf_nj"
      ],
      "metadata": {
        "id": "itM48HCWnGWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Maps: Visualizing Data with GeoDataFrames"
      ],
      "metadata": {
        "id": "k23M39fcFjI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When working with a GeoDataFrame, you can easily create informative maps by using the `.plot()` function, which allows you to visualize spatial shapes and color them based on data attributes. To make a choropleth map (a map colored by a variable), you specify which `column` to use for shading using the column argument (i.e., `\"Total_Pop\"`), and you can adjust the color style with `cmap` (color map)."
      ],
      "metadata": {
        "id": "LhzyRW-4FGJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a Map of Population by County in New Jersey\n",
        "gdf_nj.plot(column=\"Total_Pop\", cmap=\"OrRd\", legend=True, edgecolor=\"black\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VDOqGhQHo-KP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This creates a map where each county is shaded according to its population (the `Total_Pop` column), using an orange-red color scale (`\"OrRd\"`) and includes a legend for interpretation. You can further customize it by adding a title, adjusting figure size, or overlaying additional layers using Matplotlib axes."
      ],
      "metadata": {
        "id": "_UjXnFbao--R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü´µ Incorporating Your Own Data"
      ],
      "metadata": {
        "id": "T99ESX4uJoiH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We finally get to incorporate the data you've collected for your teams. The following code provides a guideline to\n",
        "\n",
        "1.   Import your own dataset and convert it into a GeoDataFrame\n",
        "2.   Merge your dataset with census data\n",
        "3.   Explore datasets available for Newark\n",
        "\n"
      ],
      "metadata": {
        "id": "IErUxOjKvTBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#We'll need to install a few more packagaes for this next section\n",
        "#%% capture #uncomment this line to hide the output from installing packages\n",
        "!pip install contextily\n",
        "!pip install mapclassify\n",
        "!pip install censusdata"
      ],
      "metadata": {
        "id": "o5qr0VPSLf7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have your survey dataset loaded, the next step is to prepare it for mapping ‚Äî the process of turning raw coordinate data into points on a map. This begins by extracting latitude and longitude values from the GPS coordinates column, which are initially stored as text. By splitting this string into two separate numeric columns, you make it possible to create geographic features that mapping software can understand.\n",
        "\n",
        "After converting the coordinates into numbers, you generate a new column of geometric points, where each point represents a location where someone filled out the survey. These points are created using the longitude and latitude values, and they form the basis of spatial analysis. To enable full mapping functionality, the dataset is then converted into a GeoDataFrame ‚Äî a special format that combines tabular data with geographic information. Assigning the correct coordinate reference system ensures that your data aligns properly with real-world locations.\n",
        "\n",
        "Finally, by using a simple interactive plotting tool, you can quickly visualize the geographic spread of your data. Each point on the map represents a survey response, allowing you to begin exploring patterns, clusters, or gaps in the coverage. This transformation from spreadsheet-style data to mapped points is a foundational step in geospatial analysis and helps bring the data to life in a way that is intuitive and visually powerful."
      ],
      "metadata": {
        "id": "cF76Fp3ESyFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "from shapely.geometry import Point\n",
        "\n",
        "# Load the county-level shapefile\n",
        "url_fakedata = \"https://raw.githubusercontent.com/cdefinnda/Python-Intro/main/Datasets/geopandas/newark_fake_environmental_survey.csv\"\n",
        "fake_dataset = pd.read_csv(url_fakedata)\n",
        "#Let's see the first five rows of the dataset\n",
        "fake_dataset.head()\n",
        "\n",
        "#Let's convert it to a GeoDataFrame\n",
        "# Step 1: Split the string into latitude and longitude\n",
        "fake_dataset[['lat', 'lon']] = fake_dataset['Enter the GPS Coordinates'].str.split(',', expand=True)\n",
        "fake_dataset['lat'] = fake_dataset['lat'].astype(float)\n",
        "fake_dataset['lon'] = fake_dataset['lon'].astype(float)\n",
        "\n",
        "# Step 2: Create geometry column\n",
        "fake_dataset['geometry'] = fake_dataset.apply(lambda row: Point(row['lon'], row['lat']), axis=1)\n",
        "\n",
        "# Step 3: Convert to GeoDataFrame\n",
        "fake_dataset_gdf = gpd.GeoDataFrame(fake_dataset, geometry='geometry', crs='EPSG:4326')\n",
        "#If we plot it, it will just be a bunch of scatter points, we need a map to understand this\n",
        "fake_dataset_gdf.explore() #This is a quick way to view a GeoDataFrame"
      ],
      "metadata": {
        "id": "895e4SkMxMEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the map above is interactive and quick to make, it's not very customizable. Let's design a map where we have more control. Below, we will add a \"basemap\" this is the underlying map we want our data to be plotted on. In the first example, we use \"OpenStreetMap\"."
      ],
      "metadata": {
        "id": "mGjoSm0ON0UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import contextily as ctx  # <-- for adding basemap\n",
        "\n",
        "# Plot with basemap\n",
        "fig, ax = plt.subplots(figsize=(25, 7))\n",
        "fake_dataset_gdf = fake_dataset_gdf.to_crs(epsg=3857)\n",
        "fake_dataset_gdf.plot(ax=ax, color='red', markersize=15, alpha=0.8)\n",
        "\n",
        "# Add basemap\n",
        "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "laRpJI6ePmH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenStreetMap has many submap vairations: 'Mapnik', 'DE', 'FR', 'HOT', 'BZH', 'CH'\n",
        "\n",
        "For example, change this line:\n",
        "```\n",
        "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
        "```\n",
        "to be replaced with:\n",
        "```\n",
        "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.DE)\n",
        "```\n",
        "\n",
        "Try the other variations to see what happens"
      ],
      "metadata": {
        "id": "nUZxx60OPsCV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In addition, OpenStreetMap can be replaced with other basemaps. For example, change this line:\n",
        "```\n",
        "ctx.add_basemap(ax, source=ctx.providers.OpenStreetMap.Mapnik)\n",
        "```\n",
        "to be replaced with:\n",
        "```\n",
        "ctx.add_basemap(ax, source=ctx.providers.MapTilesAPI.Mapnik)\n",
        "```\n",
        "\n",
        "'MapTilesAPI', 'OpenSeaMap', 'OPNVKarte', 'OpenTopoMap', 'OpenRailwayMap', 'OpenFireMap', 'SafeCast', 'Stadia', 'Thunderforest', 'BaseMapDE', 'CyclOSM', 'Jawg', 'MapBox', 'MapTiler', 'TomTom', 'Esri', 'OpenWeatherMap', 'HERE', 'HEREv3', 'FreeMapSK', 'MtbMap', 'CartoDB', 'HikeBike', 'BasemapAT', 'nlmaps', 'NASAGIBS', 'NLS', 'JusticeMap', 'GeoportailFrance', 'OneMapSG', 'USGS', 'WaymarkedTrails', 'OpenAIP', 'OpenSnowMap', 'AzureMaps', 'SwissFederalGeoportal', 'TopPlusOpen', 'Gaode', 'Strava', 'OrdnanceSurvey', 'UN'\n",
        "\n",
        "If it doesn't work, try investigating to see if there's a submap variation that you have to specify. Use this code to print out the categories:\n",
        "```\n",
        "ctx.providers.OpenStreetMap.keys()\n",
        "```\n"
      ],
      "metadata": {
        "id": "AbxQH8S4Og2g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Incorporating US Census Data\n",
        "Once your geographic survey data is mapped, you might want to bring in additional data to help explain patterns or deepen your analysis. A powerful source for this is the U.S. Census ‚Äî specifically, the American Community Survey (ACS), which provides detailed estimates about communities across the country. In this example, we pull in ACS data on median household income for Essex County, New Jersey, which includes the city of Newark.\n",
        "\n",
        "To do this, we first identify the location using FIPS codes, which are standardized numeric codes for every state and county in the U.S. New Jersey‚Äôs FIPS code is 34, and Essex County‚Äôs is 013. These codes tell the census API exactly where to look.\n",
        "\n",
        "Next, we download data from the ACS 5-Year Estimates for 2021. We ask for data at the block group level, which is a very fine scale of geography ‚Äî useful for neighborhood-level analysis. The specific variable we‚Äôre pulling is B19013_001E, which represents the median household income.\n",
        "\n",
        "Once the data is downloaded, it needs a little clean-up. The first step is resetting the index so we can work with the geographic information more easily. We also rename the income column to something more readable.\n",
        "\n",
        "Each row in the dataset is tied to a geographic area, and we need to build a unique ID for each one called a GEOID. This ID is created by stitching together the codes for state, county, census tract, and block group. It allows us to match this data later with shapefiles or maps.\n",
        "\n",
        "Finally, we remove rows that contain missing or invalid data ‚Äî in this case, any block group with the placeholder value -666666666, which the Census uses to represent unavailable income estimates.\n",
        "\n",
        "By the end of this process, we have a clean dataset showing median household income for each small neighborhood in Essex County ‚Äî ready to be mapped, compared, or combined with other data sources to better understand economic conditions in Newark."
      ],
      "metadata": {
        "id": "NjMkXU4TTqqb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import censusdata\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "\n",
        "# Newark is in Essex County, NJ\n",
        "STATE_FIPS = \"34\"   # New Jersey\n",
        "COUNTY_FIPS = \"013\" # Essex County\n",
        "\n",
        "#Let's try a different census dataset\n",
        "# Download ACS 5-year estimate data for Median household income 2021 at block group level\n",
        "# Variable B08126_001E = Median household income\n",
        "df_census = censusdata.download(\n",
        "    src=\"acs5\",\n",
        "    year=2021,\n",
        "    geo=censusdata.censusgeo([\n",
        "        (\"state\", STATE_FIPS),\n",
        "        (\"county\", COUNTY_FIPS),\n",
        "        (\"tract\", \"*\"),\n",
        "        (\"block group\", \"*\")\n",
        "    ]),\n",
        "    var=[\"B19013_001E\"]\n",
        ")\n",
        "\n",
        "# Reset index and rename columns\n",
        "df_census.reset_index(inplace=True)\n",
        "df_census = df_census.rename(columns={\"B19013_001E\": \"Median household income\"})\n",
        "\n",
        "# Extract GEOID properly\n",
        "def extract_geoid(geo):\n",
        "    fips_parts = {level: code for level, code in geo.geo}\n",
        "    return fips_parts[\"state\"] + fips_parts[\"county\"] + fips_parts[\"tract\"] + fips_parts[\"block group\"]\n",
        "\n",
        "df_census[\"GEOID\"] = df_census[\"index\"].apply(extract_geoid)\n",
        "\n",
        "df_census = df_census[df_census[\"Median household income\"] != -666666666]\n",
        "\n",
        "\n",
        "df_census.head()"
      ],
      "metadata": {
        "id": "sclwrL4Ypfsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the census data is not a GeoDataFrame, let's turn it into one now."
      ],
      "metadata": {
        "id": "3DOW2c-a7TwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "#This part is opening a dataset called \"Newark Census Blocks 2020\" which has the census data that is also geospatially mapped\n",
        "url = \"https://raw.githubusercontent.com/cdefinnda/Python-Intro/main/Datasets/geopandas/Newark_Census_Blocks_2020.zip\"\n",
        "zip_path = \"/content/Newark_Census_Blocks_2020.zip\"\n",
        "extract_path = \"/content/Newark_Census_Blocks_2020\"\n",
        "\n",
        "# Use curl to download the ZIP file\n",
        "!curl -o {zip_path} \"{url}\"\n",
        "\n",
        "# Extract ZIP contents\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "#Load block group shapefile for NJ\n",
        "gdf_blocks = gpd.read_file('/content/Newark_Census_Blocks_2020/Newark_Census_Blocks_2020/Newark_Census_Blocks_2020.shp')\n",
        "\n",
        "\n",
        "#Let's merge the two datasets togehter. 1) the original census data we opened in the previous cell merged with 2) the geolocated census data\n",
        "gdf_blocks[\"GEOID\"] = gdf_blocks[\"GEOID\"].str[:12]\n",
        "\n",
        "merged = gdf_blocks.merge(df_census, on=\"GEOID\")\n",
        "#Let's view it in a plot\n",
        "\n",
        "merged.plot()"
      ],
      "metadata": {
        "id": "6UTkAAdB7Exk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's combine the fake dataset with the census data. The fake dataset has gps coordinates while the census data is in block groups. We will plot the fake dataset as points on top of the census data block groups"
      ],
      "metadata": {
        "id": "FkaKgzQ9AESL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import contextily as ctx  # <-- for adding basemap\n",
        "\n",
        "# Plot with basemap\n",
        "fig, ax = plt.subplots(figsize=(25, 7))\n",
        "fake_dataset_gdf = fake_dataset_gdf.to_crs(epsg=3857) #ensure the coordinate reference systems (crs) is the same for each dataset\n",
        "merged = merged.to_crs(epsg=3857)\n",
        "\n",
        "merged.plot(\n",
        "    ax=ax,\n",
        "    column='Median household income',  # the column to visualize\n",
        "    cmap='cool',                       # colormap (e.g., 'OrRd', 'Viridis', 'Blues')\n",
        "    legend=True,                       # show legend\n",
        "    edgecolor='black',                 # outlines\n",
        "    linewidth=0.3                      # thinner borders\n",
        ")\n",
        "\n",
        "fake_dataset_gdf.plot(ax=ax, color='red', markersize=15, alpha=0.8)\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "51gExosouu5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a few other datasets you can use for Newark. Try combining them with the"
      ],
      "metadata": {
        "id": "2J5sXPij7vn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "red_url = \"https://raw.githubusercontent.com/cdefinnda/Python-Intro/main/Datasets/geopandas/mappinginequality.json\"\n",
        "Redlining = gpd.read_file(red_url)\n",
        "NJ_Redlining = Redlining[(Redlining['state'] == 'NJ')]\n",
        "Essex_Redlining = NJ_Redlining[(NJ_Redlining['city'] == 'Essex Co.')]\n",
        "#We will color the map based on the grading of the redlining\n",
        "# If 'grade' is NaN, fill it from 'category'\n",
        "Essex_Redlining['grade'] = Essex_Redlining['grade'].fillna('Unknown')\n",
        "\n",
        "color_map = {\n",
        "    'A': '#228B22',  # Green\n",
        "    'B': '#0096FF',  # Blue\n",
        "    'C': '#c6bf6e',  # Yellow-brown\n",
        "    'D': '#cb6976',  # Pink-red\n",
        "    'Industrial': '#808080',\n",
        "    'Industrial and Commercial': '#8C8984',\n",
        "    'Unknown': '#808080',\n",
        "}\n",
        "\n",
        "# Assign colors based on the grade\n",
        "Essex_Redlining['color'] = Essex_Redlining['grade'].map(color_map)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "Essex_Redlining.plot(facecolor=Essex_Redlining['color'], edgecolor='black', ax=ax)\n",
        "\n",
        "# Add a title\n",
        "plt.title('Redlining Map: Essex County, NJ', fontsize=15)\n",
        "\n",
        "# Turn off axes\n",
        "ax.set_axis_off()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3uS8Pkv9AUE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's isolate this to just the city of Newark. What You Want: gpd.overlay() for spatial intersection\n",
        "To intersect two shapefiles based on their geometries, use geopandas.overlay(..., how='intersection')."
      ],
      "metadata": {
        "id": "qpafLr6YRW-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://raw.githubusercontent.com/cdefinnda/Python-Intro/main/Datasets/geopandas/Newark_Wards.zip\"\n",
        "zip_path = '/content/Newark_Wards.zip'\n",
        "extract_path = \"/content/Newark_Wards\"\n",
        "\n",
        "# Use curl to download the ZIP file\n",
        "!curl -o {zip_path} \"{url}\"\n",
        "\n",
        "# Extract ZIP contents\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "#Load block group shapefile for NJ (if available)\n",
        "Wards = gpd.read_file('/content/Newark_Wards/Newark_Geographies/Newark_Wards.shp')\n",
        "\n",
        "# Make sure both GeoDataFrames have the same CRS\n",
        "Essex_Redlining = Essex_Redlining.to_crs(Wards.crs)\n",
        "\n",
        "# Perform spatial intersection (only overlapping areas remain)#We will merge the redlining dataset with the wards dataset and have only the the intersecting map remaining.\n",
        "Newark_Redlining = gpd.overlay(Essex_Redlining, Wards, how='intersection')\n",
        "\n",
        "# Plot result\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "Newark_Redlining.plot(facecolor=Newark_Redlining['color'], edgecolor='black', ax=ax)\n",
        "\n",
        "# Add a title\n",
        "plt.title('Redlining Map: Newark, NJ', fontsize=15)\n",
        "\n",
        "# Turn off axes\n",
        "ax.set_axis_off()\n"
      ],
      "metadata": {
        "id": "ycM4KNcORWvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you‚Äôve mapped your survey points and brought in additional data, it‚Äôs helpful to add background layers like roads, buildings, or neighborhood boundaries. These give your map real-world context and make it easier to interpret. In this section, we demonstrate how to download and map street-level shapefiles for Newark, New Jersey.\n",
        "\n",
        "We begin by downloading a ZIP file from an online source. This ZIP file contains multiple files that make up a shapefile ‚Äî a common format for geographic data that includes points, lines, or polygons. In this case, the shapefile contains line features that represent streets in Newark.\n",
        "\n",
        "Using Python‚Äôs zipfile module, we extract the contents of the ZIP file into a folder. Once extracted, we use GeoPandas to read the shapefile and load it into a GeoDataFrame called Streets.\n",
        "\n",
        "Now we‚Äôre ready to create a map. In this example, we color the streets based on the \"TYPE\" column, which likely indicates the kind of street (such as major road, local road, etc.). Each type is assigned a different color using the \"tab10\" color palette, which is designed to clearly show categories. The legend=True option adds a key so viewers can see what each color represents.\n",
        "\n",
        "We customize the appearance by:\n",
        "\n",
        "Setting the line width to make the streets easier to see\n",
        "Turning off the axes for a cleaner look\n",
        "Adding a title to explain what the map shows\n",
        "Finally, we use plt.tight_layout() and plt.show() to display the map.\n",
        "\n",
        "This kind of base map layer is useful when you're adding other features ‚Äî like survey points, census boundaries, or bubble maps ‚Äî because it gives your audience something familiar to help orient them. You can build on this map by adding more layers, combining it with other datasets, or using it as a reference for community analysis."
      ],
      "metadata": {
        "id": "kGFb9cnfytUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "url = \"https://raw.githubusercontent.com/cdefinnda/Python-Intro/main/Datasets/geopandas/newark_streets.zip\"\n",
        "zip_path = \"/content/newark_streets.zip\"\n",
        "extract_path = \"/content/newark_streets\"\n",
        "\n",
        "# Use curl to download the ZIP file\n",
        "!curl -o {zip_path} \"{url}\"\n",
        "\n",
        "# Extract ZIP contents\n",
        "with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "#Load block group shapefile for NJ (if available)\n",
        "Streets = gpd.read_file('/content/newark_streets/newark_streets/newark_streets.shp')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "Streets.plot(\n",
        "    ax=ax,\n",
        "    column='TYPE',         # Use this to color by a column\n",
        "    legend=True,           # Show legend\n",
        "    linewidth=1.0,         # Thickness of lines\n",
        "    cmap='tab10',          # Good for categorical data (alternatives: 'Set1', 'Accent')\n",
        "    legend_kwds={'title': 'Street Type'}\n",
        ")\n",
        "Newark_Redlining = Newark_Redlining.to_crs(Streets.crs)\n",
        "\n",
        "#--Uncomment the line below to overlay streets with the redlining data\n",
        "#Newark_Redlining.plot(facecolor=Newark_Redlining['color'], edgecolor='black', ax=ax, alpha = 0.5)\n",
        "\n",
        "ax.set_title(\"Newark Streets by Type\", fontsize=14)\n",
        "ax.set_axis_off()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aNpjK7HHS44n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8Lb24MySUw0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other datasources to use:  \n",
        "\n",
        "*   NJ list of all datasets: https://drive.google.com/file/d/14YYKtV0bMynbSDWpX5WrJzhJak-pE0GW/view\n",
        "*  NJ GIS Datasets:\n",
        " https://njogis-newjersey.opendata.arcgis.com/search\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "678fP88tZyz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü§ì Advanced: Different mapping styles and customizing your maps"
      ],
      "metadata": {
        "id": "KXSmsevswgn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you‚Äôve cleaned and geocoded your dataset, the next step is visualization ‚Äî bringing your data to life through maps. Mapping helps uncover spatial patterns and relationships that are hard to see in tables or charts. This section introduces different mapping styles you can use in Python with GeoPandas and other libraries.\n",
        "\n",
        "We begin with a bubble map, a type of point map where each location is marked by a circle, and the size of the circle represents a value ‚Äî in this case, the number of surveillance cameras reported at each location. This helps you quickly see which areas have higher or lower counts.\n",
        "\n",
        "To make the map more readable, we add a basemap of city streets in the background using the contextily package. This provides helpful geographic context so viewers can recognize familiar streets and neighborhoods. We also choose a color map (cmap) to shade the circles based on their values ‚Äî in this example, red to blue (coolwarm) ‚Äî which adds another visual dimension to the data.\n",
        "\n",
        "The size of each circle is scaled up to make differences more visible. If the numbers are small or large, you can adjust the multiplication factor (e.g., * 10) to get the right visual balance.\n",
        "\n",
        "Here's what‚Äôs happening in the code:\n",
        "\n",
        "plot() maps the data using a column of values to control color.\n",
        "markersize= scales the dots according to the variable.\n",
        "ctx.add_basemap() overlays the city map.\n",
        "The axis is turned off for a cleaner look.\n",
        "Finally, we display the map with plt.show().\n",
        "\n",
        "For more map styles (like choropleths, categorical maps, or heatmaps), check out the GeoPandas mapping guide.\n",
        "\n",
        "The following section will demonstrate different mapping styles. See this website for more: https://geopandas.org/en/stable/docs/user_guide/mapping.html"
      ],
      "metadata": {
        "id": "dZVaIafdwLEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bubble Map: This map has the streets in the background so we can see exactly where each dot is in the city."
      ],
      "metadata": {
        "id": "jj_OTlkD6tvd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "fake_dataset_gdf.plot(\n",
        "    ax=ax,\n",
        "    column='Number of surveillance cameras (e.g., CCTV, security cameras)',        # replace with your real numeric column\n",
        "    cmap='coolwarm',\n",
        "    legend=True,\n",
        "    markersize=fake_dataset_gdf['Number of surveillance cameras (e.g., CCTV, security cameras)'] * 10  # adjust scale if needed\n",
        ")\n",
        "ax.set_title(\"Bubble Map: Bigger Circles = More Cameras\", fontsize=14)\n",
        "ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron)\n",
        "\n",
        "ax.set_axis_off()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ePMQKdwI6JzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interactive** **maps**: https://plotly.com/python/maps/\n",
        "If you want more advanced interactivity ‚Äî like zooming, hovering, or clicking on a point to see its details ‚Äî you can explore interactive maps using tools like Plotly. These let you build maps that respond to the viewer, making them great for presentations or dashboards.\n"
      ],
      "metadata": {
        "id": "kA8n60tR6Vsx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s216XlkkssjE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": "40",
        "lenType": 16,
        "lenVar": "100"
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q7hJEYWvG0_6",
        "T99ESX4uJoiH",
        "KXSmsevswgn8"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}